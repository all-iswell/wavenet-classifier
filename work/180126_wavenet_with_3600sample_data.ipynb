{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aeatda/anaconda3/envs/proj3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "from datetime import datetime\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.python.client import timeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../_data/combined_csv/180126_3600samp_cry386_laugh703_with_ids_mu_law.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SAMPLE_SIZE = 3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filter_width          2\n",
      "sample_rate           22050\n",
      "dilations             [1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1, 2, 4, 8, 16, 32, 64, 128, 256, 512]\n",
      "residual_channels     16\n",
      "dilation_channels     16\n",
      "quantization_channels 256\n",
      "skip_channels         16\n",
      "use_biases            True\n",
      "scalar_input          False\n",
      "initial_filter_width  32\n"
     ]
    }
   ],
   "source": [
    "wavenet_params = {\n",
    "    \"filter_width\": 2,\n",
    "    \"sample_rate\": 22050,\n",
    "    \"dilations\": [1, 2, 4, 8, 16, 32, 64, 128, 256, 512,\n",
    "                  1, 2, 4, 8, 16, 32, 64, 128, 256, 512],\n",
    "    \"residual_channels\": 16,\n",
    "    \"dilation_channels\": 16,\n",
    "    \"quantization_channels\": 256,\n",
    "    \"skip_channels\": 16,\n",
    "    \"use_biases\": True,\n",
    "    \"scalar_input\": False,\n",
    "    \"initial_filter_width\": 32\n",
    "}\n",
    "\n",
    "for key in wavenet_params.keys():\n",
    "    exec('{} = wavenet_params[\\'{}\\']'.format(key, key))\n",
    "    print('{:21}'.format(key), eval(key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper functions for WaveNetModel class\n",
    "\n",
    "def create_variable(name, shape):\n",
    "    '''Create a convolution filter variable with the specified name and shape,\n",
    "    and initialize it using Xavier initialition.'''\n",
    "    initializer = tf.contrib.layers.xavier_initializer_conv2d()\n",
    "    variable = tf.Variable(initializer(shape=shape), name=name)\n",
    "    return variable\n",
    "\n",
    "\n",
    "def create_embedding_table(name, shape):\n",
    "    if shape[0] == shape[1]:\n",
    "        # Make a one-hot encoding as the initial value.\n",
    "        initial_val = np.identity(n=shape[0], dtype=np.float32)\n",
    "        return tf.Variable(initial_val, name=name)\n",
    "    else:\n",
    "        return create_variable(name, shape)\n",
    "\n",
    "\n",
    "def create_bias_variable(name, shape):\n",
    "    '''Create a bias variable with the specified name and shape and initialize\n",
    "    it to zero.'''\n",
    "    initializer = tf.constant_initializer(value=0.0, dtype=tf.float32)\n",
    "    return tf.Variable(initializer(shape=shape), name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# time_to_batch, batch_to_time, causal_conv\n",
    "\n",
    "def time_to_batch(value, dilation, name=None):\n",
    "    with tf.name_scope('time_to_batch'):\n",
    "        shape = tf.shape(value)\n",
    "        pad_elements = dilation - 1 - (shape[1] + dilation - 1) % dilation\n",
    "        padded = tf.pad(value, [[0, 0], [0, pad_elements], [0, 0]])\n",
    "        reshaped = tf.reshape(padded, [-1, dilation, shape[2]])\n",
    "        transposed = tf.transpose(reshaped, perm=[1, 0, 2])\n",
    "        return tf.reshape(transposed, [shape[0] * dilation, -1, shape[2]])\n",
    "\n",
    "\n",
    "def batch_to_time(value, dilation, name=None):\n",
    "    with tf.name_scope('batch_to_time'):\n",
    "        shape = tf.shape(value)\n",
    "        prepared = tf.reshape(value, [dilation, -1, shape[2]])\n",
    "        transposed = tf.transpose(prepared, perm=[1, 0, 2])\n",
    "        return tf.reshape(transposed,\n",
    "                          [tf.div(shape[0], dilation), -1, shape[2]])\n",
    "\n",
    "\n",
    "def causal_conv(value, filter_, dilation, name='causal_conv'):\n",
    "    with tf.name_scope(name):\n",
    "        filter_width = tf.shape(filter_)[0]\n",
    "        if dilation > 1:\n",
    "            transformed = time_to_batch(value, dilation)\n",
    "            conv = tf.nn.conv1d(transformed, filter_, stride=1,\n",
    "                                padding='VALID')\n",
    "            restored = batch_to_time(conv, dilation)\n",
    "        else:\n",
    "            restored = tf.nn.conv1d(value, filter_, stride=1, padding='VALID')\n",
    "        # Remove excess elements at the end.\n",
    "        out_width = tf.shape(value)[1] - (filter_width - 1) * dilation\n",
    "        result = tf.slice(restored,\n",
    "                          [0, 0, 0],\n",
    "                          [-1, out_width, -1])\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## scalar_input option does not work now\n",
    "\n",
    "class WaveNetModel(object):\n",
    "    '''WaveNet model modified for binary classification.\n",
    "    Modified by John Choi (isnbh0)\n",
    "\n",
    "    Default parameters:\n",
    "        dilations = [2**i for i in range(10)] * 2\n",
    "        filter_width = 2  # Convolutions just use 2 samples.\n",
    "        residual_channels = 16  # Not specified in the paper.\n",
    "        dilation_channels = 16  # Not specified in the paper.\n",
    "        skip_channels = 16      # Not specified in the paper.\n",
    "        net = WaveNetModel(batch_size, dilations, filter_width,\n",
    "                           residual_channels, dilation_channels,\n",
    "                           skip_channels)\n",
    "        loss = net.loss(input_batch)\n",
    "    '''\n",
    "\n",
    "    def __init__(self,\n",
    "                 batch_size,\n",
    "                 dilations,\n",
    "                 filter_width,\n",
    "                 residual_channels,\n",
    "                 dilation_channels,\n",
    "                 skip_channels,\n",
    "                 quantization_channels=2**8,\n",
    "                 use_biases=False,\n",
    "                 scalar_input=False,\n",
    "                 initial_filter_width=32,\n",
    "                 histograms=False):\n",
    "        '''Initializes the WaveNet model.\n",
    "\n",
    "        Args:\n",
    "            batch_size: audio files per batch (recommended: 1).\n",
    "            dilations: A list with the dilation factor for each layer.\n",
    "            filter_width: The samples that are included in each convolution,\n",
    "                after dilating.\n",
    "            residual_channels: # filters to learn for the residual.\n",
    "            dilation_channels: # filters to learn for the dilated convolution.\n",
    "            skip_channels: # filters to learn that contribute to the\n",
    "                quantized softmax output.\n",
    "            quantization_channels: # amplitude values to use for audio\n",
    "                quantization and the corresponding one-hot encoding.\n",
    "                Default: 256 (8-bit quantization).\n",
    "            use_biases: Whether to add a bias layer to each convolution.\n",
    "                Default: False.\n",
    "            scalar_input: Whether to use the quantized waveform directly as\n",
    "            |   input to the network instead of one-hot encoding it.\n",
    "            |   Default: False.\n",
    "            *-initial_filter_width: The width of the initial filter of the\n",
    "                convolution applied to the scalar input. This is only relevant\n",
    "                if scalar_input=True.\n",
    "            histograms: Whether to store histograms in the summary.\n",
    "                Default: False.\n",
    "\n",
    "\n",
    "        '''\n",
    "        self.batch_size = batch_size\n",
    "        self.dilations = dilations\n",
    "        self.filter_width = filter_width\n",
    "        self.residual_channels = residual_channels\n",
    "        self.dilation_channels = dilation_channels\n",
    "        self.quantization_channels = quantization_channels\n",
    "        self.use_biases = use_biases\n",
    "        self.skip_channels = skip_channels\n",
    "        self.scalar_input = scalar_input\n",
    "        self.initial_filter_width = initial_filter_width\n",
    "        self.histograms = histograms\n",
    "\n",
    "        self.receptive_field = WaveNetModel.calculate_receptive_field(\n",
    "            self.filter_width, self.dilations, self.scalar_input,\n",
    "            self.initial_filter_width)\n",
    "        self.variables = self._create_variables()\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_receptive_field(filter_width, dilations, scalar_input,\n",
    "                                  initial_filter_width):\n",
    "        receptive_field = (filter_width - 1) * sum(dilations) + 1\n",
    "        if scalar_input:\n",
    "            receptive_field += initial_filter_width - 1\n",
    "        else:\n",
    "            receptive_field += filter_width - 1\n",
    "        return receptive_field\n",
    "\n",
    "    def _create_variables(self):\n",
    "        '''This function creates all variables used by the network.\n",
    "        This allows us to share them between multiple calls to the loss\n",
    "        function and generation function.'''\n",
    "\n",
    "        var = dict()\n",
    "\n",
    "        with tf.variable_scope('wavenet'):\n",
    "            with tf.variable_scope('causal_layer'):\n",
    "                layer = dict()\n",
    "                if self.scalar_input:\n",
    "                    initial_channels = 1\n",
    "                    initial_filter_width = self.initial_filter_width\n",
    "                else:\n",
    "                    initial_channels = self.quantization_channels\n",
    "                    initial_filter_width = self.filter_width\n",
    "                layer['filter'] = create_variable(\n",
    "                    'filter',\n",
    "                    [initial_filter_width,\n",
    "                     initial_channels,\n",
    "                     self.residual_channels])\n",
    "                var['causal_layer'] = layer\n",
    "\n",
    "            var['dilated_stack'] = list()\n",
    "            with tf.variable_scope('dilated_stack'):\n",
    "                for i, dilation in enumerate(self.dilations):\n",
    "                    with tf.variable_scope('layer{}'.format(i)):\n",
    "                        current = dict()\n",
    "                        current['filter'] = create_variable(\n",
    "                            'filter',\n",
    "                            [self.filter_width,\n",
    "                             self.residual_channels,\n",
    "                             self.dilation_channels])\n",
    "                        current['gate'] = create_variable(\n",
    "                            'gate',\n",
    "                            [self.filter_width,\n",
    "                             self.residual_channels,\n",
    "                             self.dilation_channels])\n",
    "                        current['dense'] = create_variable(\n",
    "                            'dense',\n",
    "                            [1,\n",
    "                             self.dilation_channels,\n",
    "                             self.residual_channels])\n",
    "                        current['skip'] = create_variable(\n",
    "                            'skip',\n",
    "                            [1,\n",
    "                             self.dilation_channels,\n",
    "                             self.skip_channels])\n",
    "\n",
    "\n",
    "\n",
    "                        if self.use_biases:\n",
    "                            current['filter_bias'] = create_bias_variable(\n",
    "                                'filter_bias',\n",
    "                                [self.dilation_channels])\n",
    "                            current['gate_bias'] = create_bias_variable(\n",
    "                                'gate_bias',\n",
    "                                [self.dilation_channels])\n",
    "                            current['dense_bias'] = create_bias_variable(\n",
    "                                'dense_bias',\n",
    "                                [self.residual_channels])\n",
    "                            current['skip_bias'] = create_bias_variable(\n",
    "                                'slip_bias',\n",
    "                                [self.skip_channels])\n",
    "\n",
    "                        var['dilated_stack'].append(current)\n",
    "\n",
    "            with tf.variable_scope('postprocessing'):\n",
    "                current = dict()\n",
    "                current['postprocess1'] = create_variable(\n",
    "                    'postprocess1',\n",
    "                    [1, self.skip_channels, self.skip_channels])\n",
    "                current['postprocess2'] = create_variable(\n",
    "                    'postprocess2',\n",
    "                    [1, self.skip_channels, 1])  ## returns scalar value\n",
    "                if self.use_biases:\n",
    "                    current['postprocess1_bias'] = create_bias_variable(\n",
    "                        'postprocess1_bias',\n",
    "                        [self.skip_channels])\n",
    "                    current['postprocess2_bias'] = create_bias_variable(\n",
    "                        'postprocess2_bias',\n",
    "                        [1])\n",
    "                var['postprocessing'] = current\n",
    "\n",
    "        return var\n",
    "\n",
    "    def _create_causal_layer(self, input_batch):\n",
    "        '''Creates a single causal convolution layer.\n",
    "\n",
    "        The layer can change the number of channels.\n",
    "        '''\n",
    "        with tf.name_scope('causal_layer'):\n",
    "            weights_filter = self.variables['causal_layer']['filter']\n",
    "            return causal_conv(input_batch, weights_filter, 1)\n",
    "\n",
    "    def _create_dilation_layer(self, input_batch, layer_index, dilation,\n",
    "                               output_width):\n",
    "        '''Creates a single causal dilated convolution layer.\n",
    "\n",
    "        Args:\n",
    "             input_batch: Input to the dilation layer.\n",
    "             layer_index: Integer indicating which layer this is.\n",
    "             dilation: Integer specifying the dilation size.\n",
    "\n",
    "        The layer contains a gated filter that connects to dense output\n",
    "        and to a skip connection:\n",
    "\n",
    "               |-> [gate]   -|        |-> 1x1 conv -> skip output\n",
    "               |             |-> (*) -|\n",
    "        input -|-> [filter] -|        |-> 1x1 conv -|\n",
    "               |                                    |-> (+) -> dense output\n",
    "               |------------------------------------|\n",
    "\n",
    "        Where `[gate]` and `[filter]` are causal convolutions with a\n",
    "        non-linear activation at the output. Biases and global conditioning\n",
    "        are omitted due to the limits of ASCII art.\n",
    "\n",
    "        '''\n",
    "        variables = self.variables['dilated_stack'][layer_index]\n",
    "\n",
    "        weights_filter = variables['filter']\n",
    "        weights_gate = variables['gate']\n",
    "\n",
    "        conv_filter = causal_conv(input_batch, weights_filter, dilation)\n",
    "        conv_gate = causal_conv(input_batch, weights_gate, dilation)\n",
    "\n",
    "\n",
    "        if self.use_biases:\n",
    "            filter_bias = variables['filter_bias']\n",
    "            gate_bias = variables['gate_bias']\n",
    "            conv_filter = tf.add(conv_filter, filter_bias)\n",
    "            conv_gate = tf.add(conv_gate, gate_bias)\n",
    "\n",
    "        out = tf.tanh(conv_filter) * tf.sigmoid(conv_gate)\n",
    "\n",
    "        # The 1x1 conv to produce the residual output\n",
    "        weights_dense = variables['dense']\n",
    "        transformed = tf.nn.conv1d(\n",
    "            out, weights_dense, stride=1, padding=\"SAME\", name=\"dense\")\n",
    "\n",
    "        # The 1x1 conv to produce the skip output\n",
    "        skip_cut = tf.shape(out)[1] - output_width\n",
    "        out_skip = tf.slice(out, [0, skip_cut, 0], [-1, -1, -1])\n",
    "        weights_skip = variables['skip']\n",
    "        skip_contribution = tf.nn.conv1d(\n",
    "            out_skip, weights_skip, stride=1, padding=\"SAME\", name=\"skip\")\n",
    "\n",
    "        if self.use_biases:\n",
    "            dense_bias = variables['dense_bias']\n",
    "            skip_bias = variables['skip_bias']\n",
    "            transformed = transformed + dense_bias\n",
    "            skip_contribution = skip_contribution + skip_bias\n",
    "\n",
    "        if self.histograms:\n",
    "            layer = 'layer{}'.format(layer_index)\n",
    "            tf.summary.histogram(layer + '_filter', weights_filter)\n",
    "            tf.summary.histogram(layer + '_gate', weights_gate)\n",
    "            tf.summary.histogram(layer + '_dense', weights_dense)\n",
    "            tf.summary.histogram(layer + '_skip', weights_skip)\n",
    "            if self.use_biases:\n",
    "                tf.summary.histogram(layer + '_biases_filter', filter_bias)\n",
    "                tf.summary.histogram(layer + '_biases_gate', gate_bias)\n",
    "                tf.summary.histogram(layer + '_biases_dense', dense_bias)\n",
    "                tf.summary.histogram(layer + '_biases_skip', skip_bias)\n",
    "\n",
    "        input_cut = tf.shape(input_batch)[1] - tf.shape(transformed)[1]\n",
    "        input_batch = tf.slice(input_batch, [0, input_cut, 0], [-1, -1, -1])\n",
    "\n",
    "        return skip_contribution, input_batch + transformed\n",
    "\n",
    "    def _generator_conv(self, input_batch, state_batch, weights):\n",
    "        '''Perform convolution for a single convolutional processing step.'''\n",
    "        # TODO generalize to filter_width > 2\n",
    "        past_weights = weights[0, :, :]\n",
    "        curr_weights = weights[1, :, :]\n",
    "        output = tf.matmul(state_batch, past_weights) + tf.matmul(\n",
    "            input_batch, curr_weights)\n",
    "        return output\n",
    "\n",
    "    def _generator_causal_layer(self, input_batch, state_batch):\n",
    "        with tf.name_scope('causal_layer'):\n",
    "            weights_filter = self.variables['causal_layer']['filter']\n",
    "            output = self._generator_conv(\n",
    "                input_batch, state_batch, weights_filter)\n",
    "        return output\n",
    "\n",
    "    def _generator_dilation_layer(self, input_batch, state_batch, layer_index,\n",
    "                                  dilation):\n",
    "        variables = self.variables['dilated_stack'][layer_index]\n",
    "\n",
    "        weights_filter = variables['filter']\n",
    "        weights_gate = variables['gate']\n",
    "        output_filter = self._generator_conv(\n",
    "            input_batch, state_batch, weights_filter)\n",
    "        output_gate = self._generator_conv(\n",
    "            input_batch, state_batch, weights_gate)\n",
    "\n",
    "        if self.use_biases:\n",
    "            output_filter = output_filter + variables['filter_bias']\n",
    "            output_gate = output_gate + variables['gate_bias']\n",
    "\n",
    "        out = tf.tanh(output_filter) * tf.sigmoid(output_gate)\n",
    "\n",
    "        weights_dense = variables['dense']\n",
    "        transformed = tf.matmul(out, weights_dense[0, :, :])\n",
    "        if self.use_biases:\n",
    "            transformed = transformed + variables['dense_bias']\n",
    "\n",
    "        weights_skip = variables['skip']\n",
    "        skip_contribution = tf.matmul(out, weights_skip[0, :, :])\n",
    "        if self.use_biases:\n",
    "            skip_contribution = skip_contribution + variables['skip_bias']\n",
    "\n",
    "        return skip_contribution, input_batch + transformed\n",
    "\n",
    "    def _create_network(self, input_batch):\n",
    "        '''Construct the WaveNet network.'''\n",
    "        outputs = []\n",
    "        current_layer = input_batch\n",
    "\n",
    "        # Pre-process the input with a regular convolution\n",
    "        if self.scalar_input:\n",
    "            initial_channels = 1\n",
    "        else:\n",
    "            initial_channels = self.quantization_channels\n",
    "\n",
    "        current_layer = self._create_causal_layer(current_layer)\n",
    "\n",
    "        output_width = tf.shape(input_batch)[1] - self.receptive_field + 1\n",
    "\n",
    "        # Add all defined dilation layers.\n",
    "        with tf.name_scope('dilated_stack'):\n",
    "            for layer_index, dilation in enumerate(self.dilations):\n",
    "                with tf.name_scope('layer{}'.format(layer_index)):\n",
    "                    output, current_layer = self._create_dilation_layer(\n",
    "                        current_layer, layer_index, dilation,\n",
    "                        output_width)\n",
    "                    outputs.append(output)\n",
    "\n",
    "        with tf.name_scope('postprocessing'):\n",
    "            # Perform (+) -> ReLU -> 1x1 conv -> ReLU -> 1x1 conv to\n",
    "            # postprocess the output.\n",
    "            w1 = self.variables['postprocessing']['postprocess1']\n",
    "            w2 = self.variables['postprocessing']['postprocess2']\n",
    "            if self.use_biases:\n",
    "                b1 = self.variables['postprocessing']['postprocess1_bias']\n",
    "                b2 = self.variables['postprocessing']['postprocess2_bias']\n",
    "\n",
    "            if self.histograms:\n",
    "                tf.summary.histogram('postprocess1_weights', w1)\n",
    "                tf.summary.histogram('postprocess2_weights', w2)\n",
    "                if self.use_biases:\n",
    "                    tf.summary.histogram('postprocess1_biases', b1)\n",
    "                    tf.summary.histogram('postprocess2_biases', b2)\n",
    "\n",
    "            # We skip connections from the outputs of each layer, adding them\n",
    "            # all up here.\n",
    "            total = sum(outputs)\n",
    "            transformed1 = tf.nn.relu(total)\n",
    "            conv1 = tf.nn.conv1d(transformed1, w1, stride=1, padding=\"SAME\")\n",
    "            if self.use_biases:\n",
    "                conv1 = tf.add(conv1, b1)\n",
    "            transformed2 = tf.nn.relu(conv1)\n",
    "            conv2 = tf.nn.conv1d(transformed2, w2, stride=1, padding=\"SAME\")\n",
    "            if self.use_biases:\n",
    "                conv2 = tf.add(conv2, b2)\n",
    "\n",
    "            ## ADDED CODE HERE. ******************************\n",
    "            ## RELU activation before going to dense node\n",
    "            transformed3 = tf.nn.relu(conv2)\n",
    "\n",
    "            ## Reshape to 2-D tensor with dimensions\n",
    "            ## batch_size, sample_size\n",
    "            ## shape[1] constant here so we can use dense\n",
    "            shape = [tf.shape(transformed3)[0], SAMPLE_SIZE - sum(dilations) - 1]\n",
    "            transformed3 = tf.reshape(transformed3, shape)\n",
    "            \n",
    "            ## Add dense layer to transform from\n",
    "            ## batch_size x sample_size 2-D array to\n",
    "            ## batch_size 1-D array\n",
    "            final = tf.layers.dense(transformed3, units=1, reuse=tf.AUTO_REUSE,\n",
    "                                    name='final_out')\n",
    "        return final\n",
    "\n",
    "    def _one_hot(self, input_batch, batch_size=None):\n",
    "        '''One-hot encodes the waveform amplitudes.\n",
    "\n",
    "        This allows the definition of the network as a categorical distribution\n",
    "        over a finite set of possible amplitudes.\n",
    "        '''\n",
    "        if not batch_size:\n",
    "            batch_size = self.batch_size\n",
    "            \n",
    "        with tf.name_scope('one_hot_encode'):\n",
    "            encoded = tf.one_hot(\n",
    "                input_batch,\n",
    "                depth=self.quantization_channels,\n",
    "                dtype=tf.float32)\n",
    "            shape = [batch_size, -1, self.quantization_channels]\n",
    "            encoded = tf.reshape(encoded, shape)\n",
    "        return encoded\n",
    "\n",
    "    def predict_proba(self, waveform, name='wavenet'):\n",
    "        '''Computes the probability of waveform being LAUGHTER.\n",
    "           Necessary for evaluation with test data.'''\n",
    "        ## TODO\n",
    "        ## tf.losses.sigmoid_cross_entropy(y_, train_out)\n",
    "        with tf.name_scope(name):\n",
    "            ## slice off rightmost end of input where labels are stored\n",
    "            ## input_batch transformed into input_audio\n",
    "            input_audio = tf.slice(waveform, begin=[0, 0, 0], size=[-1, SAMPLE_SIZE, -1])\n",
    "            input_label = tf.slice(waveform, begin=[0, SAMPLE_SIZE, 0], size=[-1, 1, -1])\n",
    "            \n",
    "            input_audio = tf.to_int32(input_audio)\n",
    "\n",
    "\n",
    "        with tf.name_scope(name):\n",
    "            if self.scalar_input:\n",
    "                encoded = tf.cast(waveform, tf.float32)\n",
    "                encoded = tf.reshape(encoded, [-1, 1])\n",
    "            else:\n",
    "                encoded = self._one_hot(input_audio,\n",
    "                                       batch_size=1)  # arg changed from waveform\n",
    "\n",
    "            raw_output = self._create_network(encoded)\n",
    "            raw_output = tf.reshape(raw_output, [-1])\n",
    "            out = tf.nn.sigmoid(raw_output)\n",
    "\n",
    "            return out\n",
    "\n",
    "        \n",
    "    def loss(self,\n",
    "             input_batch,\n",
    "             input_label=None,\n",
    "             name='wavenet'):\n",
    "        '''Creates a WaveNet network and returns crossentropy loss.\n",
    "\n",
    "        The variables are all scoped to the given name.\n",
    "        '''\n",
    "## tf.losses.sigmoid_cross_entropy(y_, train_out)\n",
    "        with tf.name_scope(name):\n",
    "            if input_label is None:\n",
    "                ## slice off rightmost end of input where labels are stored\n",
    "                ## input_batch transformed into input_audio\n",
    "                y_idx = tf.shape(input_batch)[1] - 1\n",
    "                input_audio = tf.slice(input_batch, begin=[0, 0, 0], size=[-1, SAMPLE_SIZE, -1])\n",
    "                input_label = tf.slice(input_batch, begin=[0, SAMPLE_SIZE, 0], size=[-1, 1, -1])\n",
    "            else:\n",
    "                input_audio = input_batch\n",
    "                input_label = tf.reshape(input_label, [-1, 1, 1])\n",
    "            ## mu-law encode disabled because using preprocessed data\n",
    "            # encoded_input = mu_law_encode(input_batch,\n",
    "            #                             self.quantization_channels)\n",
    "            input_audio = tf.to_int32(input_audio)\n",
    "            encoded = self._one_hot(input_audio)  # arg changed from encoded_input\n",
    "            if self.scalar_input:\n",
    "                network_input = tf.reshape(\n",
    "                    tf.cast(input_batch, tf.float32),\n",
    "                    [self.batch_size, -1, 1])\n",
    "            else:\n",
    "                network_input = encoded\n",
    "\n",
    "              ## omitted for classification use\n",
    "#             # Cut off the last sample of network input to preserve causality.\n",
    "#             network_input_width = tf.shape(network_input)[1] - 1\n",
    "#             network_input = tf.slice(network_input, [0, 0, 0],\n",
    "#                                      [-1, network_input_width, -1])\n",
    "\n",
    "            ## shape of raw_output is (batch_size, 1)\n",
    "            raw_output = self._create_network(network_input)\n",
    "\n",
    "            with tf.name_scope('loss'):\n",
    "                ## format the target values\n",
    "                target_output = tf.reshape(input_label, [self.batch_size])\n",
    "                ## logits\n",
    "                prediction = tf.reshape(raw_output, [self.batch_size])\n",
    "             \n",
    "                loss = tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "                    logits=prediction,\n",
    "                    labels=target_output)\n",
    "                reduced_loss = tf.reduce_mean(loss)\n",
    "\n",
    "                tf.summary.scalar('loss', reduced_loss)\n",
    "\n",
    "                return reduced_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "batch_size = 40\n",
    "learning_rate = 1e-3\n",
    "momentum = 0.9\n",
    "\n",
    "net = WaveNetModel(batch_size=batch_size, dilations=dilations, filter_width=filter_width,\n",
    "                   residual_channels=residual_channels, dilation_channels=dilation_channels,\n",
    "                   skip_channels=skip_channels,\n",
    "                   histograms=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df0 = df.sample(1089).copy()\n",
    "df1 = df0.iloc[:1000, :]\n",
    "df_test = df0.iloc[1000:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch1 = df1.sample(batch_size).iloc[:, 2:3603].values\n",
    "batch1 = batch1.reshape(batch_size, -1, 1)\n",
    "\n",
    "batch1_tensor = tf.Variable(batch1, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "loss = net.loss(batch1_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'wavenet_1/loss/Mean:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.MomentumOptimizer(learning_rate=1e-3,\n",
    "                                       momentum=0.9)\n",
    "trainable = tf.trainable_variables()\n",
    "optim = optimizer.minimize(loss, var_list=trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writer = tf.summary.FileWriter('./tf_logs/train/{}'\n",
    "                        .format(datetime.now().strftime(\"%y%m%d_%H%M%S\")))\n",
    "writer.add_graph(tf.get_default_graph())\n",
    "run_metadata = tf.RunMetadata()\n",
    "summaries = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up session\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=False))\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "# saver code not used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step   1:  loss = 0.692998\n",
      "step   2:  loss = 0.692980\n",
      "step   3:  loss = 0.692946\n",
      "step   4:  loss = 0.692897\n",
      "step   5:  loss = 0.692835\n",
      "CPU times: user 1min 31s, sys: 3.4 s, total: 1min 34s\n",
      "Wall time: 19 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for step in range(5):\n",
    "    summ_, loss_, _ = sess.run([summaries, loss, optim])\n",
    "    writer.add_summary(summ_, step)\n",
    "    print(\"step {:3}:  loss = {:8.6f}\".format(step+1, loss_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_test = df_test.sample(1).iloc[:, 2:3603].values\n",
    "batch_test = batch_test.reshape(1, -1, 1)\n",
    "\n",
    "batch_test_tensor = tf.Variable(batch_test, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sound_id</th>\n",
       "      <th>start_idx</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>3591</th>\n",
       "      <th>3592</th>\n",
       "      <th>3593</th>\n",
       "      <th>3594</th>\n",
       "      <th>3595</th>\n",
       "      <th>3596</th>\n",
       "      <th>3597</th>\n",
       "      <th>3598</th>\n",
       "      <th>3599</th>\n",
       "      <th>laugh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>364959</td>\n",
       "      <td>16000</td>\n",
       "      <td>153.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>...</td>\n",
       "      <td>170.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>407459</td>\n",
       "      <td>41000</td>\n",
       "      <td>153.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>...</td>\n",
       "      <td>82.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 3603 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sound_id  start_idx      0      1      2     3      4      5      6  \\\n",
       "995    364959      16000  153.0  141.0  102.0  92.0   98.0   93.0   84.0   \n",
       "460    407459      41000  153.0  100.0  119.0  92.0  131.0  168.0  146.0   \n",
       "\n",
       "        7  ...     3591   3592   3593   3594   3595   3596   3597   3598  \\\n",
       "995  87.0  ...    170.0  166.0  148.0  116.0  104.0  107.0  144.0  152.0   \n",
       "460  88.0  ...     82.0  101.0  149.0  184.0  138.0   62.0  160.0  184.0   \n",
       "\n",
       "      3599  laugh  \n",
       "995  152.0    1.0  \n",
       "460   83.0    1.0  \n",
       "\n",
       "[2 rows x 3603 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[df_test['0'] == batch_test[0, 0, 0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 153.],\n",
       "        [ 141.],\n",
       "        [ 102.],\n",
       "        ..., \n",
       "        [ 152.],\n",
       "        [ 152.],\n",
       "        [   1.]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable_1:0' shape=(1, 3601, 1) dtype=float32_ref>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_test_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'wavenet_3/Sigmoid:0' shape=(?,) dtype=float32>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fix this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable_1:0' shape=(1, 3601, 1) dtype=float32_ref>"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_test_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3600, 256)\n"
     ]
    }
   ],
   "source": [
    "pred = net.predict_proba(batch_test_tensor)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "pred_ = sess.run(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(pred_)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_test[0, -1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_n(n):\n",
    "    results = []\n",
    "\n",
    "    for i in range(n):\n",
    "        batch_test = df_test.sample(1).iloc[:, 2:3603].values\n",
    "        batch_test = batch_test.reshape(1, -1, 1)\n",
    "        batch_test_tensor = tf.Variable(batch_test, dtype=tf.float32)\n",
    "\n",
    "        y_true = batch_test[0, -1, 0]\n",
    "\n",
    "        pred = net.predict_proba(batch_test_tensor)\n",
    "\n",
    "        init = tf.global_variables_initializer()\n",
    "        sess.run(init)\n",
    "        pred_ = sess.run(pred)\n",
    "\n",
    "        y_pred = np.round(pred_)[0]\n",
    "\n",
    "        results.append(y_true == y_pred)\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3600, 256)\n",
      "(1, 3600, 256)\n",
      "(1, 3600, 256)\n",
      "(1, 3600, 256)\n",
      "(1, 3600, 256)\n",
      "(1, 3600, 256)\n",
      "(1, 3600, 256)\n",
      "(1, 3600, 256)\n",
      "(1, 3600, 256)\n",
      "(1, 3600, 256)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[False, False, True, True, False, True, True, True, True, False]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_n(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# making TFRecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sound_id</th>\n",
       "      <th>start_idx</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>3591</th>\n",
       "      <th>3592</th>\n",
       "      <th>3593</th>\n",
       "      <th>3594</th>\n",
       "      <th>3595</th>\n",
       "      <th>3596</th>\n",
       "      <th>3597</th>\n",
       "      <th>3598</th>\n",
       "      <th>3599</th>\n",
       "      <th>laugh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>198993</td>\n",
       "      <td>9500</td>\n",
       "      <td>69.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>...</td>\n",
       "      <td>202.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>196168</td>\n",
       "      <td>48000</td>\n",
       "      <td>189.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>...</td>\n",
       "      <td>166.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>391361</td>\n",
       "      <td>21000</td>\n",
       "      <td>161.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>...</td>\n",
       "      <td>155.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 3603 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sound_id  start_idx      0      1      2      3      4      5      6  \\\n",
       "596    198993       9500   69.0  192.0  214.0  214.0  205.0  201.0  180.0   \n",
       "455    196168      48000  189.0  188.0  148.0   99.0  112.0   87.0   84.0   \n",
       "208    391361      21000  161.0  197.0  217.0  219.0  214.0  218.0  214.0   \n",
       "\n",
       "         7  ...     3591   3592   3593   3594   3595   3596   3597   3598  \\\n",
       "596   62.0  ...    202.0  198.0  189.0  160.0   83.0   71.0   70.0   72.0   \n",
       "455  118.0  ...    166.0  171.0   80.0   86.0  186.0  186.0  170.0  181.0   \n",
       "208  206.0  ...    155.0  181.0  191.0  198.0  205.0  202.0  171.0   61.0   \n",
       "\n",
       "      3599  laugh  \n",
       "596   67.0    1.0  \n",
       "455  169.0    1.0  \n",
       "208   50.0    0.0  \n",
       "\n",
       "[3 rows x 3603 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df0 = df.sample(1089).copy()\n",
    "df1 = df0.iloc[:1000, :]\n",
    "df_test = df0.iloc[1000:1080, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_val = df1.values.astype(np.int64)\n",
    "df_test_val = df_test.values.astype(np.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path0 = '../_data/tfrecords/sample_3600_{}.tfrecord'\n",
    "def write_tfrecord(arr, name='train'):\n",
    "    global data_path0\n",
    "    data_path = data_path0.format(name)\n",
    "    num_samples = arr.shape[1] - 3\n",
    "\n",
    "    with tf.python_io.TFRecordWriter(data_path) as writer:\n",
    "        for row in arr:\n",
    "            sound_id, start_idx, samples, laugh\\\n",
    "            = row[0], row[1], row[2:num_samples+2], row[num_samples+2]\n",
    "\n",
    "            example = tf.train.Example()\n",
    "            example.features.feature[\"sound_id\"].int64_list.value.append(sound_id)\n",
    "            example.features.feature[\"start_idx\"].int64_list.value.append(start_idx)\n",
    "            example.features.feature[\"samples\"].float_list.value.extend(samples)\n",
    "            example.features.feature[\"laugh\"].float_list.value.append(laugh)\n",
    "\n",
    "            writer.write(example.SerializeToString())\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 543 ms, sys: 12.4 ms, total: 555 ms\n",
      "Wall time: 630 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "write_tfrecord(df1_val, name='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 58.4 ms, sys: 0 ns, total: 58.4 ms\n",
      "Wall time: 64.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "write_tfrecord(df_test_val, name='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parser(serialized_example):\n",
    "    features = {\n",
    "        'samples': tf.FixedLenFeature([num_samples], tf.float32),\n",
    "        'laugh' : tf.FixedLenFeature([1], tf.float32)\n",
    "    }\n",
    "    parsed_feature = tf.parse_single_example(serialized_example, features)\n",
    "    samples = parsed_feature['samples']\n",
    "    laugh = parsed_feature['laugh']\n",
    "    return samples, laugh\n",
    "\n",
    "def get_tfrecord(name='train', batch_size=1, buffer_size=5000,\n",
    "                 repeat=1, seed=None):\n",
    "    dataset = tf.data.TFRecordDataset(data_path0.format(name)).map(parser)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.shuffle(buffer_size, seed=seed)\n",
    "    dataset = dataset.repeat(repeat)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modeling with TFRecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "batch_size = 40\n",
    "learning_rate = 1e-3\n",
    "momentum = 0.9\n",
    "\n",
    "\n",
    "data_train = get_tfrecord(batch_size=batch_size, seed=0)\n",
    "itr = data_train.make_one_shot_iterator()\n",
    "sample_batch, laugh = itr.get_next()\n",
    "sample_batch = tf.reshape(sample_batch, [-1, sample_batch.shape[1], 1])\n",
    "\n",
    "\n",
    "net = WaveNetModel(batch_size=batch_size, dilations=dilations, filter_width=filter_width,\n",
    "                   residual_channels=residual_channels, dilation_channels=dilation_channels,\n",
    "                   skip_channels=skip_channels,\n",
    "                   histograms=True)\n",
    "loss = net.loss(sample_batch, laugh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.MomentumOptimizer(learning_rate=1e-3,\n",
    "                                       momentum=0.9)\n",
    "trainable = tf.trainable_variables()\n",
    "optim = optimizer.minimize(loss, var_list=trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writer = tf.summary.FileWriter('./tf_logs/train/{}'\n",
    "                        .format(datetime.now().strftime(\"%y%m%d_%H%M%S\")))\n",
    "writer.add_graph(tf.get_default_graph())\n",
    "run_metadata = tf.RunMetadata()\n",
    "summaries = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up session\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=False))\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "# saver code not used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step   1:  loss = 0.719465\n",
      "step   2:  loss = 0.690304\n",
      "step   3:  loss = 0.702621\n",
      "step   4:  loss = 0.729722\n",
      "step   5:  loss = 0.732677\n",
      "CPU times: user 1min 27s, sys: 2.63 s, total: 1min 29s\n",
      "Wall time: 14.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for step in range(5):\n",
    "    summ_, loss_, _ = sess.run([summaries, loss, optim])\n",
    "    writer.add_summary(summ_, step)\n",
    "    print(\"step {:3}:  loss = {:8.6f}\".format(step+1, loss_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (proj3)",
   "language": "python",
   "name": "proj3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
