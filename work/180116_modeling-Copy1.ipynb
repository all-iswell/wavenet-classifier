{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ops.py\n",
    "from __future__ import division\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# model.py\n",
    "import numpy as np\n",
    "#import tensorflow as tf\n",
    "# from .ops import causal_conv, mu_law_encode\n",
    "\n",
    "\n",
    "# train.py\n",
    "\"\"\"Training script for the WaveNet network on the VCTK corpus.\n",
    "This script trains a network with the WaveNet using data from the VCTK corpus,\n",
    "which can be freely downloaded at the following site (~10 GB):\n",
    "http://homepages.inf.ed.ac.uk/jyamagis/page3/page58/page58.html\n",
    "\"\"\"\n",
    "from __future__ import print_function\n",
    "import argparse\n",
    "from datetime import datetime\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "#import tensorflow as tf\n",
    "from tensorflow.python.client import timeline\n",
    "\n",
    "# from wavenet import WaveNetModel, AudioReader, optimizer_factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavenet_params = {\n",
    "    \"filter_width\": 2,\n",
    "    \"sample_rate\": 22050,\n",
    "    \"dilations\": [1, 2, 4, 8, 16, 32, 64, 128, 256, 512,\n",
    "                  1, 2, 4, 8, 16, 32, 64, 128, 256, 512,\n",
    "                  1, 2, 4, 8, 16, 32, 64, 128, 256, 512],\n",
    "    \"residual_channels\": 16,\n",
    "    \"dilation_channels\": 16,\n",
    "    \"quantization_channels\": 256,\n",
    "    \"skip_channels\": 16,\n",
    "    \"use_biases\": True,\n",
    "    \"scalar_input\": False,\n",
    "    \"initial_filter_width\": 32\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_adam_optimizer(learning_rate, momentum):\n",
    "    return tf.train.AdamOptimizer(learning_rate=learning_rate,\n",
    "                                  epsilon=1e-4)\n",
    "\n",
    "\n",
    "def create_sgd_optimizer(learning_rate, momentum):\n",
    "    return tf.train.MomentumOptimizer(learning_rate=learning_rate,\n",
    "                                      momentum=momentum)\n",
    "\n",
    "\n",
    "def create_rmsprop_optimizer(learning_rate, momentum):\n",
    "    return tf.train.RMSPropOptimizer(learning_rate=learning_rate,\n",
    "                                     momentum=momentum,\n",
    "                                     epsilon=1e-5)\n",
    "\n",
    "\n",
    "optimizer_factory = {'adam': create_adam_optimizer,\n",
    "                     'sgd': create_sgd_optimizer,\n",
    "                     'rmsprop': create_rmsprop_optimizer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def time_to_batch(value, dilation, name=None):\n",
    "    with tf.name_scope('time_to_batch'):\n",
    "        shape = tf.shape(value)\n",
    "        pad_elements = dilation - 1 - (shape[1] + dilation - 1) % dilation\n",
    "        padded = tf.pad(value, [[0, 0], [0, pad_elements], [0, 0]])\n",
    "        reshaped = tf.reshape(padded, [-1, dilation, shape[2]])\n",
    "        transposed = tf.transpose(reshaped, perm=[1, 0, 2])\n",
    "        return tf.reshape(transposed, [shape[0] * dilation, -1, shape[2]])\n",
    "\n",
    "\n",
    "def batch_to_time(value, dilation, name=None):\n",
    "    with tf.name_scope('batch_to_time'):\n",
    "        shape = tf.shape(value)\n",
    "        prepared = tf.reshape(value, [dilation, -1, shape[2]])\n",
    "        transposed = tf.transpose(prepared, perm=[1, 0, 2])\n",
    "        return tf.reshape(transposed,\n",
    "                          [tf.div(shape[0], dilation), -1, shape[2]])\n",
    "\n",
    "\n",
    "def causal_conv(value, filter_, dilation, name='causal_conv'):\n",
    "    with tf.name_scope(name):\n",
    "        filter_width = tf.shape(filter_)[0]\n",
    "        if dilation > 1:\n",
    "            transformed = time_to_batch(value, dilation)\n",
    "            conv = tf.nn.conv1d(transformed, filter_, stride=1,\n",
    "                                padding='VALID')\n",
    "            restored = batch_to_time(conv, dilation)\n",
    "        else:\n",
    "            restored = tf.nn.conv1d(value, filter_, stride=1, padding='VALID')\n",
    "        # Remove excess elements at the end.\n",
    "        out_width = tf.shape(value)[1] - (filter_width - 1) * dilation\n",
    "        result = tf.slice(restored,\n",
    "                          [0, 0, 0],\n",
    "                          [-1, out_width, -1])\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mu_law_encode(audio, quantization_channels):\n",
    "    '''Quantizes waveform amplitudes.'''\n",
    "    with tf.name_scope('encode'):\n",
    "        mu = tf.to_float(quantization_channels - 1)\n",
    "        # Perform mu-law companding transformation (ITU-T, 1988).\n",
    "        # Minimum operation is here to deal with rare large amplitudes caused\n",
    "        # by resampling.\n",
    "        safe_audio_abs = tf.minimum(tf.abs(audio), 1.0)\n",
    "        magnitude = tf.log1p(mu * safe_audio_abs) / tf.log1p(mu)\n",
    "        signal = tf.sign(audio) * magnitude\n",
    "        # Quantize signal to the specified number of levels.\n",
    "        return tf.to_int32((signal + 1) / 2 * mu + 0.5)\n",
    "\n",
    "\n",
    "def mu_law_decode(output, quantization_channels):\n",
    "    '''Recovers waveform from quantized values.'''\n",
    "    with tf.name_scope('decode'):\n",
    "        mu = quantization_channels - 1\n",
    "        # Map values back to [-1, 1].\n",
    "        signal = 2 * (tf.to_float(output) / mu) - 1\n",
    "        # Perform inverse of mu-law transformation.\n",
    "        magnitude = (1 / mu) * ((1 + mu)**abs(signal) - 1)\n",
    "        return tf.sign(signal) * magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model.py\n",
    "\n",
    "\n",
    "def create_variable(name, shape):\n",
    "    '''Create a convolution filter variable with the specified name and shape,\n",
    "    and initialize it using Xavier initialition.'''\n",
    "    initializer = tf.contrib.layers.xavier_initializer_conv2d()\n",
    "    variable = tf.Variable(initializer(shape=shape), name=name)\n",
    "    return variable\n",
    "\n",
    "\n",
    "def create_embedding_table(name, shape):\n",
    "    if shape[0] == shape[1]:\n",
    "        # Make a one-hot encoding as the initial value.\n",
    "        initial_val = np.identity(n=shape[0], dtype=np.float32)\n",
    "        return tf.Variable(initial_val, name=name)\n",
    "    else:\n",
    "        return create_variable(name, shape)\n",
    "\n",
    "\n",
    "def create_bias_variable(name, shape):\n",
    "    '''Create a bias variable with the specified name and shape and initialize\n",
    "    it to zero.'''\n",
    "    initializer = tf.constant_initializer(value=0.0, dtype=tf.float32)\n",
    "    return tf.Variable(initializer(shape=shape), name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaveNetModel(object):\n",
    "    '''Implements the WaveNet network for generative audio.\n",
    "\n",
    "    Usage (with the architecture as in the DeepMind paper):\n",
    "        dilations = [2**i for i in range(N)] * M\n",
    "        filter_width = 2  # Convolutions just use 2 samples.\n",
    "        residual_channels = 16  # Not specified in the paper.\n",
    "        dilation_channels = 32  # Not specified in the paper.\n",
    "        skip_channels = 16      # Not specified in the paper.\n",
    "        net = WaveNetModel(batch_size, dilations, filter_width,\n",
    "                           residual_channels, dilation_channels,\n",
    "                           skip_channels)\n",
    "        loss = net.loss(input_batch)\n",
    "    '''\n",
    "\n",
    "    def __init__(self,\n",
    "                 batch_size,\n",
    "                 dilations,\n",
    "                 filter_width,\n",
    "                 residual_channels,\n",
    "                 dilation_channels,\n",
    "                 skip_channels,\n",
    "                 quantization_channels=2**8,\n",
    "                 use_biases=False,\n",
    "                 scalar_input=False,\n",
    "                 initial_filter_width=32,\n",
    "                 histograms=False):\n",
    "        '''Initializes the WaveNet model.\n",
    "\n",
    "        Args:\n",
    "            batch_size: How many audio files are supplied per batch\n",
    "                (recommended: 1).\n",
    "            dilations: A list with the dilation factor for each layer.\n",
    "            filter_width: The samples that are included in each convolution,\n",
    "                after dilating.\n",
    "            residual_channels: How many filters to learn for the residual.\n",
    "            dilation_channels: How many filters to learn for the dilated\n",
    "                convolution.\n",
    "            skip_channels: How many filters to learn that contribute to the\n",
    "                quantized softmax output.\n",
    "            quantization_channels: How many amplitude values to use for audio\n",
    "                quantization and the corresponding one-hot encoding.\n",
    "                Default: 256 (8-bit quantization).\n",
    "            use_biases: Whether to add a bias layer to each convolution.\n",
    "                Default: False.\n",
    "            scalar_input: Whether to use the quantized waveform directly as\n",
    "                input to the network instead of one-hot encoding it.\n",
    "                Default: False.\n",
    "            initial_filter_width: The width of the initial filter of the\n",
    "                convolution applied to the scalar input. This is only relevant\n",
    "                if scalar_input=True.\n",
    "            histograms: Whether to store histograms in the summary.\n",
    "                Default: False.\n",
    "\n",
    "\n",
    "        '''\n",
    "        self.batch_size = batch_size\n",
    "        self.dilations = dilations\n",
    "        self.filter_width = filter_width\n",
    "        self.residual_channels = residual_channels\n",
    "        self.dilation_channels = dilation_channels\n",
    "        self.quantization_channels = quantization_channels\n",
    "        self.use_biases = use_biases\n",
    "        self.skip_channels = skip_channels\n",
    "        self.scalar_input = scalar_input\n",
    "        self.initial_filter_width = initial_filter_width\n",
    "        self.histograms = histograms\n",
    "\n",
    "        self.receptive_field = WaveNetModel.calculate_receptive_field(\n",
    "            self.filter_width, self.dilations, self.scalar_input,\n",
    "            self.initial_filter_width)\n",
    "        self.variables = self._create_variables()\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_receptive_field(filter_width, dilations, scalar_input,\n",
    "                                  initial_filter_width):\n",
    "        receptive_field = (filter_width - 1) * sum(dilations) + 1\n",
    "        if scalar_input:\n",
    "            receptive_field += initial_filter_width - 1\n",
    "        else:\n",
    "            receptive_field += filter_width - 1\n",
    "        return receptive_field\n",
    "\n",
    "    def _create_variables(self):\n",
    "        '''This function creates all variables used by the network.\n",
    "        This allows us to share them between multiple calls to the loss\n",
    "        function and generation function.'''\n",
    "\n",
    "        var = dict()\n",
    "\n",
    "        with tf.variable_scope('wavenet'):\n",
    "            with tf.variable_scope('causal_layer'):\n",
    "                layer = dict()\n",
    "                if self.scalar_input:\n",
    "                    initial_channels = 1\n",
    "                    initial_filter_width = self.initial_filter_width\n",
    "                else:\n",
    "                    initial_channels = self.quantization_channels\n",
    "                    initial_filter_width = self.filter_width\n",
    "                layer['filter'] = create_variable(\n",
    "                    'filter',\n",
    "                    [initial_filter_width,\n",
    "                     initial_channels,\n",
    "                     self.residual_channels])\n",
    "                var['causal_layer'] = layer\n",
    "\n",
    "            var['dilated_stack'] = list()\n",
    "            with tf.variable_scope('dilated_stack'):\n",
    "                for i, dilation in enumerate(self.dilations):\n",
    "                    with tf.variable_scope('layer{}'.format(i)):\n",
    "                        current = dict()\n",
    "                        current['filter'] = create_variable(\n",
    "                            'filter',\n",
    "                            [self.filter_width,\n",
    "                             self.residual_channels,\n",
    "                             self.dilation_channels])\n",
    "                        current['gate'] = create_variable(\n",
    "                            'gate',\n",
    "                            [self.filter_width,\n",
    "                             self.residual_channels,\n",
    "                             self.dilation_channels])\n",
    "                        current['dense'] = create_variable(\n",
    "                            'dense',\n",
    "                            [1,\n",
    "                             self.dilation_channels,\n",
    "                             self.residual_channels])\n",
    "                        current['skip'] = create_variable(\n",
    "                            'skip',\n",
    "                            [1,\n",
    "                             self.dilation_channels,\n",
    "                             self.skip_channels])\n",
    "\n",
    "\n",
    "\n",
    "                        if self.use_biases:\n",
    "                            current['filter_bias'] = create_bias_variable(\n",
    "                                'filter_bias',\n",
    "                                [self.dilation_channels])\n",
    "                            current['gate_bias'] = create_bias_variable(\n",
    "                                'gate_bias',\n",
    "                                [self.dilation_channels])\n",
    "                            current['dense_bias'] = create_bias_variable(\n",
    "                                'dense_bias',\n",
    "                                [self.residual_channels])\n",
    "                            current['skip_bias'] = create_bias_variable(\n",
    "                                'slip_bias',\n",
    "                                [self.skip_channels])\n",
    "\n",
    "                        var['dilated_stack'].append(current)\n",
    "\n",
    "            with tf.variable_scope('postprocessing'):\n",
    "                current = dict()\n",
    "                current['postprocess1'] = create_variable(\n",
    "                    'postprocess1',\n",
    "                    [1, self.skip_channels, self.skip_channels])\n",
    "                current['postprocess2'] = create_variable(\n",
    "                    'postprocess2',\n",
    "                    [1, self.skip_channels, 1])\n",
    "                if self.use_biases:\n",
    "                    current['postprocess1_bias'] = create_bias_variable(\n",
    "                        'postprocess1_bias',\n",
    "                        [self.skip_channels])\n",
    "                    current['postprocess2_bias'] = create_bias_variable(\n",
    "                        'postprocess2_bias',\n",
    "                        [1])\n",
    "                var['postprocessing'] = current\n",
    "\n",
    "        return var\n",
    "\n",
    "    def _create_causal_layer(self, input_batch):\n",
    "        '''Creates a single causal convolution layer.\n",
    "\n",
    "        The layer can change the number of channels.\n",
    "        '''\n",
    "        with tf.name_scope('causal_layer'):\n",
    "            weights_filter = self.variables['causal_layer']['filter']\n",
    "            return causal_conv(input_batch, weights_filter, 1)\n",
    "\n",
    "    def _create_dilation_layer(self, input_batch, layer_index, dilation,\n",
    "                               output_width):\n",
    "        '''Creates a single causal dilated convolution layer.\n",
    "\n",
    "        Args:\n",
    "             input_batch: Input to the dilation layer.\n",
    "             layer_index: Integer indicating which layer this is.\n",
    "             dilation: Integer specifying the dilation size.\n",
    "\n",
    "        The layer contains a gated filter that connects to dense output\n",
    "        and to a skip connection:\n",
    "\n",
    "               |-> [gate]   -|        |-> 1x1 conv -> skip output\n",
    "               |             |-> (*) -|\n",
    "        input -|-> [filter] -|        |-> 1x1 conv -|\n",
    "               |                                    |-> (+) -> dense output\n",
    "               |------------------------------------|\n",
    "\n",
    "        Where `[gate]` and `[filter]` are causal convolutions with a\n",
    "        non-linear activation at the output. Biases and global conditioning\n",
    "        are omitted due to the limits of ASCII art.\n",
    "\n",
    "        '''\n",
    "        variables = self.variables['dilated_stack'][layer_index]\n",
    "\n",
    "        weights_filter = variables['filter']\n",
    "        weights_gate = variables['gate']\n",
    "\n",
    "        conv_filter = causal_conv(input_batch, weights_filter, dilation)\n",
    "        conv_gate = causal_conv(input_batch, weights_gate, dilation)\n",
    "\n",
    "\n",
    "        if self.use_biases:\n",
    "            filter_bias = variables['filter_bias']\n",
    "            gate_bias = variables['gate_bias']\n",
    "            conv_filter = tf.add(conv_filter, filter_bias)\n",
    "            conv_gate = tf.add(conv_gate, gate_bias)\n",
    "\n",
    "        out = tf.tanh(conv_filter) * tf.sigmoid(conv_gate)\n",
    "\n",
    "        # The 1x1 conv to produce the residual output\n",
    "        weights_dense = variables['dense']\n",
    "        transformed = tf.nn.conv1d(\n",
    "            out, weights_dense, stride=1, padding=\"SAME\", name=\"dense\")\n",
    "\n",
    "        # The 1x1 conv to produce the skip output\n",
    "        skip_cut = tf.shape(out)[1] - output_width\n",
    "        out_skip = tf.slice(out, [0, skip_cut, 0], [-1, -1, -1])\n",
    "        weights_skip = variables['skip']\n",
    "        skip_contribution = tf.nn.conv1d(\n",
    "            out_skip, weights_skip, stride=1, padding=\"SAME\", name=\"skip\")\n",
    "\n",
    "        if self.use_biases:\n",
    "            dense_bias = variables['dense_bias']\n",
    "            skip_bias = variables['skip_bias']\n",
    "            transformed = transformed + dense_bias\n",
    "            skip_contribution = skip_contribution + skip_bias\n",
    "\n",
    "        if self.histograms:\n",
    "            layer = 'layer{}'.format(layer_index)\n",
    "            tf.histogram_summary(layer + '_filter', weights_filter)\n",
    "            tf.histogram_summary(layer + '_gate', weights_gate)\n",
    "            tf.histogram_summary(layer + '_dense', weights_dense)\n",
    "            tf.histogram_summary(layer + '_skip', weights_skip)\n",
    "            if self.use_biases:\n",
    "                tf.histogram_summary(layer + '_biases_filter', filter_bias)\n",
    "                tf.histogram_summary(layer + '_biases_gate', gate_bias)\n",
    "                tf.histogram_summary(layer + '_biases_dense', dense_bias)\n",
    "                tf.histogram_summary(layer + '_biases_skip', skip_bias)\n",
    "\n",
    "        input_cut = tf.shape(input_batch)[1] - tf.shape(transformed)[1]\n",
    "        input_batch = tf.slice(input_batch, [0, input_cut, 0], [-1, -1, -1])\n",
    "\n",
    "        return skip_contribution, input_batch + transformed\n",
    "\n",
    "    def _generator_conv(self, input_batch, state_batch, weights):\n",
    "        '''Perform convolution for a single convolutional processing step.'''\n",
    "        # TODO generalize to filter_width > 2\n",
    "        past_weights = weights[0, :, :]\n",
    "        curr_weights = weights[1, :, :]\n",
    "        output = tf.matmul(state_batch, past_weights) + tf.matmul(\n",
    "            input_batch, curr_weights)\n",
    "        return output\n",
    "\n",
    "    def _generator_causal_layer(self, input_batch, state_batch):\n",
    "        with tf.name_scope('causal_layer'):\n",
    "            weights_filter = self.variables['causal_layer']['filter']\n",
    "            output = self._generator_conv(\n",
    "                input_batch, state_batch, weights_filter)\n",
    "        return output\n",
    "\n",
    "    def _generator_dilation_layer(self, input_batch, state_batch, layer_index,\n",
    "                                  dilation):\n",
    "        variables = self.variables['dilated_stack'][layer_index]\n",
    "\n",
    "        weights_filter = variables['filter']\n",
    "        weights_gate = variables['gate']\n",
    "        output_filter = self._generator_conv(\n",
    "            input_batch, state_batch, weights_filter)\n",
    "        output_gate = self._generator_conv(\n",
    "            input_batch, state_batch, weights_gate)\n",
    "\n",
    "        if self.use_biases:\n",
    "            output_filter = output_filter + variables['filter_bias']\n",
    "            output_gate = output_gate + variables['gate_bias']\n",
    "\n",
    "        out = tf.tanh(output_filter) * tf.sigmoid(output_gate)\n",
    "\n",
    "        weights_dense = variables['dense']\n",
    "        transformed = tf.matmul(out, weights_dense[0, :, :])\n",
    "        if self.use_biases:\n",
    "            transformed = transformed + variables['dense_bias']\n",
    "\n",
    "        weights_skip = variables['skip']\n",
    "        skip_contribution = tf.matmul(out, weights_skip[0, :, :])\n",
    "        if self.use_biases:\n",
    "            skip_contribution = skip_contribution + variables['skip_bias']\n",
    "\n",
    "        return skip_contribution, input_batch + transformed\n",
    "\n",
    "    def _create_network(self, input_batch):\n",
    "        '''Construct the WaveNet network.'''\n",
    "        outputs = []\n",
    "        current_layer = input_batch\n",
    "\n",
    "        # Pre-process the input with a regular convolution\n",
    "        if self.scalar_input:\n",
    "            initial_channels = 1\n",
    "        else:\n",
    "            initial_channels = self.quantization_channels\n",
    "\n",
    "        current_layer = self._create_causal_layer(current_layer)\n",
    "\n",
    "        output_width = tf.shape(input_batch)[1] - self.receptive_field + 1\n",
    "\n",
    "        # Add all defined dilation layers.\n",
    "        with tf.name_scope('dilated_stack'):\n",
    "            for layer_index, dilation in enumerate(self.dilations):\n",
    "                with tf.name_scope('layer{}'.format(layer_index)):\n",
    "                    output, current_layer = self._create_dilation_layer(\n",
    "                        current_layer, layer_index, dilation,\n",
    "                        output_width)\n",
    "                    outputs.append(output)\n",
    "\n",
    "        with tf.name_scope('postprocessing'):\n",
    "            # Perform (+) -> ReLU -> 1x1 conv -> ReLU -> 1x1 conv to\n",
    "            # postprocess the output.\n",
    "            w1 = self.variables['postprocessing']['postprocess1']\n",
    "            w2 = self.variables['postprocessing']['postprocess2']\n",
    "            if self.use_biases:\n",
    "                b1 = self.variables['postprocessing']['postprocess1_bias']\n",
    "                b2 = self.variables['postprocessing']['postprocess2_bias']\n",
    "\n",
    "            if self.histograms:\n",
    "                tf.histogram_summary('postprocess1_weights', w1)\n",
    "                tf.histogram_summary('postprocess2_weights', w2)\n",
    "                if self.use_biases:\n",
    "                    tf.histogram_summary('postprocess1_biases', b1)\n",
    "                    tf.histogram_summary('postprocess2_biases', b2)\n",
    "\n",
    "            # We skip connections from the outputs of each layer, adding them\n",
    "            # all up here.\n",
    "            total = sum(outputs)\n",
    "            transformed1 = tf.nn.relu(total)\n",
    "            conv1 = tf.nn.conv1d(transformed1, w1, stride=1, padding=\"SAME\")\n",
    "            if self.use_biases:\n",
    "                conv1 = tf.add(conv1, b1)\n",
    "            transformed2 = tf.nn.relu(conv1)\n",
    "            conv2 = tf.nn.conv1d(transformed2, w2, stride=1, padding=\"SAME\")\n",
    "            if self.use_biases:\n",
    "                conv2 = tf.add(conv2, b2)\n",
    "\n",
    "        return conv2\n",
    "\n",
    "    def _create_generator(self, input_batch):\n",
    "        '''Construct an efficient incremental generator.'''\n",
    "        init_ops = []\n",
    "        push_ops = []\n",
    "        outputs = []\n",
    "        current_layer = input_batch\n",
    "\n",
    "        q = tf.FIFOQueue(\n",
    "            1,\n",
    "            dtypes=tf.float32,\n",
    "            shapes=(self.batch_size, self.quantization_channels))\n",
    "        init = q.enqueue_many(\n",
    "            tf.zeros((1, self.batch_size, self.quantization_channels)))\n",
    "\n",
    "        current_state = q.dequeue()\n",
    "        push = q.enqueue([current_layer])\n",
    "        init_ops.append(init)\n",
    "        push_ops.append(push)\n",
    "\n",
    "        current_layer = self._generator_causal_layer(\n",
    "                            current_layer, current_state)\n",
    "\n",
    "        # Add all defined dilation layers.\n",
    "        with tf.name_scope('dilated_stack'):\n",
    "            for layer_index, dilation in enumerate(self.dilations):\n",
    "                with tf.name_scope('layer{}'.format(layer_index)):\n",
    "\n",
    "                    q = tf.FIFOQueue(\n",
    "                        dilation,\n",
    "                        dtypes=tf.float32,\n",
    "                        shapes=(self.batch_size, self.residual_channels))\n",
    "                    init = q.enqueue_many(\n",
    "                        tf.zeros((dilation, self.batch_size,\n",
    "                                  self.residual_channels)))\n",
    "\n",
    "                    current_state = q.dequeue()\n",
    "                    push = q.enqueue([current_layer])\n",
    "                    init_ops.append(init)\n",
    "                    push_ops.append(push)\n",
    "\n",
    "                    output, current_layer = self._generator_dilation_layer(\n",
    "                        current_layer, current_state, layer_index, dilation)\n",
    "                    outputs.append(output)\n",
    "        self.init_ops = init_ops\n",
    "        self.push_ops = push_ops\n",
    "\n",
    "        with tf.name_scope('postprocessing'):\n",
    "            variables = self.variables['postprocessing']\n",
    "            # Perform (+) -> ReLU -> 1x1 conv -> ReLU -> 1x1 conv to\n",
    "            # postprocess the output.\n",
    "            w1 = variables['postprocess1']\n",
    "            w2 = variables['postprocess2']\n",
    "            if self.use_biases:\n",
    "                b1 = variables['postprocess1_bias']\n",
    "                b2 = variables['postprocess2_bias']\n",
    "\n",
    "            # We skip connections from the outputs of each layer, adding them\n",
    "            # all up here.\n",
    "            total = sum(outputs)\n",
    "            transformed1 = tf.nn.relu(total)\n",
    "\n",
    "            conv1 = tf.matmul(transformed1, w1[0, :, :])\n",
    "            if self.use_biases:\n",
    "                conv1 = conv1 + b1\n",
    "            transformed2 = tf.nn.relu(conv1)\n",
    "            conv2 = tf.matmul(transformed2, w2[0, :, :])\n",
    "            if self.use_biases:\n",
    "                conv2 = conv2 + b2\n",
    "\n",
    "        return conv2\n",
    "\n",
    "    def _one_hot(self, input_batch):\n",
    "        '''One-hot encodes the waveform amplitudes.\n",
    "\n",
    "        This allows the definition of the network as a categorical distribution\n",
    "        over a finite set of possible amplitudes.\n",
    "        '''\n",
    "        with tf.name_scope('one_hot_encode'):\n",
    "            encoded = tf.one_hot(\n",
    "                input_batch,\n",
    "                depth=self.quantization_channels,\n",
    "                dtype=tf.float32)\n",
    "            shape = [self.batch_size, -1, self.quantization_channels]\n",
    "            encoded = tf.reshape(encoded, shape)\n",
    "        return encoded\n",
    "\n",
    "    def predict_proba(self, waveform, name='wavenet'):\n",
    "        '''Computes the probability distribution of the next sample based on\n",
    "        all samples in the input waveform.\n",
    "        If you want to generate audio by feeding the output of the network back\n",
    "        as an input, see predict_proba_incremental for a faster alternative.'''\n",
    "        with tf.name_scope(name):\n",
    "            if self.scalar_input:\n",
    "                encoded = tf.cast(waveform, tf.float32)\n",
    "                encoded = tf.reshape(encoded, [-1, 1])\n",
    "            else:\n",
    "                encoded = self._one_hot(waveform)\n",
    "\n",
    "            raw_output = self._create_network(encoded)\n",
    "            out = tf.reshape(raw_output, [-1, self.quantization_channels])\n",
    "            # Cast to float64 to avoid bug in TensorFlow\n",
    "            proba = tf.cast(\n",
    "                tf.nn.softmax(tf.cast(out, tf.float64)), tf.float32)\n",
    "            last = tf.slice(\n",
    "                proba,\n",
    "                [tf.shape(proba)[0] - 1, 0],\n",
    "                [1, self.quantization_channels])\n",
    "            return tf.reshape(last, [-1])\n",
    "\n",
    "    def predict_proba_incremental(self, waveform,\n",
    "                                  name='wavenet'):\n",
    "        '''Computes the probability distribution of the next sample\n",
    "        incrementally, based on a single sample and all previously passed\n",
    "        samples.'''\n",
    "        if self.filter_width > 2:\n",
    "            raise NotImplementedError(\"Incremental generation does not \"\n",
    "                                      \"support filter_width > 2.\")\n",
    "        if self.scalar_input:\n",
    "            raise NotImplementedError(\"Incremental generation does not \"\n",
    "                                      \"support scalar input yet.\")\n",
    "        with tf.name_scope(name):\n",
    "            encoded = tf.one_hot(waveform, self.quantization_channels)\n",
    "            encoded = tf.reshape(encoded, [-1, self.quantization_channels])\n",
    "            raw_output = self._create_generator(encoded)\n",
    "            out = tf.reshape(raw_output, [-1, self.quantization_channels])\n",
    "            proba = tf.cast(\n",
    "                tf.nn.softmax(tf.cast(out, tf.float64)), tf.float32)\n",
    "            last = tf.slice(\n",
    "                proba,\n",
    "                [tf.shape(proba)[0] - 1, 0],\n",
    "                [1, self.quantization_channels])\n",
    "            return tf.reshape(last, [-1])\n",
    "\n",
    "    def loss(self,\n",
    "             input_batch,\n",
    "             l2_regularization_strength=None,\n",
    "             name='wavenet'):\n",
    "        '''Creates a WaveNet network and returns the autoencoding loss.\n",
    "\n",
    "        The variables are all scoped to the given name.\n",
    "        '''\n",
    "        with tf.name_scope(name):\n",
    "            # We mu-law encode and quantize the input audioform.\n",
    "            encoded_input = mu_law_encode(input_batch,\n",
    "                                          self.quantization_channels)\n",
    "\n",
    "            encoded = self._one_hot(encoded_input)\n",
    "            if self.scalar_input:\n",
    "                network_input = tf.reshape(\n",
    "                    tf.cast(input_batch, tf.float32),\n",
    "                    [self.batch_size, -1, 1])\n",
    "            else:\n",
    "                network_input = encoded\n",
    "\n",
    "            # Cut off the last sample of network input to preserve causality.\n",
    "            network_input_width = tf.shape(network_input)[1] - 1\n",
    "            network_input = tf.slice(network_input, [0, 0, 0],\n",
    "                                     [-1, network_input_width, -1])\n",
    "\n",
    "            raw_output = self._create_network(network_input)\n",
    "\n",
    "            with tf.name_scope('loss'):\n",
    "                # Cut off the samples corresponding to the receptive field\n",
    "                # for the first predicted sample.\n",
    "                target_output = tf.slice(\n",
    "                    tf.reshape(\n",
    "                        encoded,\n",
    "                        [self.batch_size, -1, self.quantization_channels]),\n",
    "                    [0, self.receptive_field, 0],\n",
    "                    [-1, -1, -1])\n",
    "                target_output = tf.reshape(target_output,\n",
    "                                           [-1, self.quantization_channels])\n",
    "                prediction = tf.reshape(raw_output,\n",
    "                                        [-1, self.quantization_channels])\n",
    "                loss = tf.nn.softmax_cross_entropy_with_logits(\n",
    "                    logits=prediction,\n",
    "                    labels=target_output)\n",
    "                reduced_loss = tf.reduce_mean(loss)\n",
    "\n",
    "                tf.summary.scalar('loss', reduced_loss)\n",
    "\n",
    "                if l2_regularization_strength is None:\n",
    "                    return reduced_loss\n",
    "                else:\n",
    "                    # L2 regularization for all trainable parameters\n",
    "                    l2_loss = tf.add_n([tf.nn.l2_loss(v)\n",
    "                                        for v in tf.trainable_variables()\n",
    "                                        if not('bias' in v.name)])\n",
    "\n",
    "                    # Add the regularization term to the loss\n",
    "                    total_loss = (reduced_loss +\n",
    "                                  l2_regularization_strength * l2_loss)\n",
    "\n",
    "                    tf.summary.scalar('l2_loss', l2_loss)\n",
    "                    tf.summary.scalar('total_loss', total_loss)\n",
    "\n",
    "                    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--batch_size BATCH_SIZE]\n",
      "                             [--data_dir DATA_DIR]\n",
      "                             [--store_metadata STORE_METADATA]\n",
      "                             [--logdir LOGDIR] [--logdir_root LOGDIR_ROOT]\n",
      "                             [--restore_from RESTORE_FROM]\n",
      "                             [--checkpoint_every CHECKPOINT_EVERY]\n",
      "                             [--num_steps NUM_STEPS]\n",
      "                             [--learning_rate LEARNING_RATE]\n",
      "                             [--wavenet_params WAVENET_PARAMS]\n",
      "                             [--sample_size SAMPLE_SIZE]\n",
      "                             [--l2_regularization_strength L2_REGULARIZATION_STRENGTH]\n",
      "                             [--silence_threshold SILENCE_THRESHOLD]\n",
      "                             [--optimizer {adam,sgd,rmsprop}]\n",
      "                             [--momentum MOMENTUM] [--histograms HISTOGRAMS]\n",
      "                             [--gc_channels GC_CHANNELS]\n",
      "                             [--max_checkpoints MAX_CHECKPOINTS]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /run/user/1000/jupyter/kernel-358e9bd2-9441-44e4-9f01-8b384ba5bd99.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aeatda/anaconda3/envs/proj3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2870: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# train.py\n",
    "\n",
    "\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "DATA_DIRECTORY = './VCTK-Corpus'\n",
    "LOGDIR_ROOT = './logdir'\n",
    "CHECKPOINT_EVERY = 50\n",
    "NUM_STEPS = int(1e5)\n",
    "LEARNING_RATE = 1e-3\n",
    "WAVENET_PARAMS = './wavenet_params.json'\n",
    "STARTED_DATESTRING = \"{0:%Y-%m-%dT%H-%M-%S}\".format(datetime.now())\n",
    "SAMPLE_SIZE = 100000\n",
    "L2_REGULARIZATION_STRENGTH = 0\n",
    "SILENCE_THRESHOLD = 0.3\n",
    "EPSILON = 0.001\n",
    "MOMENTUM = 0.9\n",
    "MAX_TO_KEEP = 5\n",
    "METADATA = False\n",
    "\n",
    "\n",
    "def get_arguments():\n",
    "    def _str_to_bool(s):\n",
    "        \"\"\"Convert string to bool (in argparse context).\"\"\"\n",
    "        if s.lower() not in ['true', 'false']:\n",
    "            raise ValueError('Argument needs to be a '\n",
    "                             'boolean, got {}'.format(s))\n",
    "        return {'true': True, 'false': False}[s.lower()]\n",
    "\n",
    "    parser = argparse.ArgumentParser(description='WaveNet example network')\n",
    "    parser.add_argument('--batch_size', type=int, default=BATCH_SIZE,\n",
    "                        help='How many wav files to process at once. Default: ' + str(BATCH_SIZE) + '.')\n",
    "    parser.add_argument('--data_dir', type=str, default=DATA_DIRECTORY,\n",
    "                        help='The directory containing the VCTK corpus.')\n",
    "    parser.add_argument('--store_metadata', type=bool, default=METADATA,\n",
    "                        help='Whether to store advanced debugging information '\n",
    "                        '(execution time, memory consumption) for use with '\n",
    "                        'TensorBoard. Default: ' + str(METADATA) + '.')\n",
    "    parser.add_argument('--logdir', type=str, default=None,\n",
    "                        help='Directory in which to store the logging '\n",
    "                        'information for TensorBoard. '\n",
    "                        'If the model already exists, it will restore '\n",
    "                        'the state and will continue training. '\n",
    "                        'Cannot use with --logdir_root and --restore_from.')\n",
    "    parser.add_argument('--logdir_root', type=str, default=None,\n",
    "                        help='Root directory to place the logging '\n",
    "                        'output and generated model. These are stored '\n",
    "                        'under the dated subdirectory of --logdir_root. '\n",
    "                        'Cannot use with --logdir.')\n",
    "    parser.add_argument('--restore_from', type=str, default=None,\n",
    "                        help='Directory in which to restore the model from. '\n",
    "                        'This creates the new model under the dated directory '\n",
    "                        'in --logdir_root. '\n",
    "                        'Cannot use with --logdir.')\n",
    "    parser.add_argument('--checkpoint_every', type=int,\n",
    "                        default=CHECKPOINT_EVERY,\n",
    "                        help='How many steps to save each checkpoint after. Default: ' + str(CHECKPOINT_EVERY) + '.')\n",
    "    parser.add_argument('--num_steps', type=int, default=NUM_STEPS,\n",
    "                        help='Number of training steps. Default: ' + str(NUM_STEPS) + '.')\n",
    "    parser.add_argument('--learning_rate', type=float, default=LEARNING_RATE,\n",
    "                        help='Learning rate for training. Default: ' + str(LEARNING_RATE) + '.')\n",
    "    parser.add_argument('--wavenet_params', type=str, default=WAVENET_PARAMS,\n",
    "                        help='JSON file with the network parameters. Default: ' + WAVENET_PARAMS + '.')\n",
    "    parser.add_argument('--sample_size', type=int, default=SAMPLE_SIZE,\n",
    "                        help='Concatenate and cut audio samples to this many '\n",
    "                        'samples. Default: ' + str(SAMPLE_SIZE) + '.')\n",
    "    parser.add_argument('--l2_regularization_strength', type=float,\n",
    "                        default=L2_REGULARIZATION_STRENGTH,\n",
    "                        help='Coefficient in the L2 regularization. '\n",
    "                        'Default: False')\n",
    "    parser.add_argument('--silence_threshold', type=float,\n",
    "                        default=SILENCE_THRESHOLD,\n",
    "                        help='Volume threshold below which to trim the start '\n",
    "                        'and the end from the training set samples. Default: ' + str(SILENCE_THRESHOLD) + '.')\n",
    "    parser.add_argument('--optimizer', type=str, default='adam',\n",
    "                        choices=optimizer_factory.keys(),\n",
    "                        help='Select the optimizer specified by this option. Default: adam.')\n",
    "    parser.add_argument('--momentum', type=float,\n",
    "                        default=MOMENTUM, help='Specify the momentum to be '\n",
    "                        'used by sgd or rmsprop optimizer. Ignored by the '\n",
    "                        'adam optimizer. Default: ' + str(MOMENTUM) + '.')\n",
    "    parser.add_argument('--histograms', type=_str_to_bool, default=False,\n",
    "                        help='Whether to store histogram summaries. Default: False')\n",
    "    parser.add_argument('--max_checkpoints', type=int, default=MAX_TO_KEEP,\n",
    "                        help='Maximum amount of checkpoints that will be kept alive. Default: '\n",
    "                             + str(MAX_TO_KEEP) + '.')\n",
    "    return parser.parse_args()\n",
    "\n",
    "\n",
    "def save(saver, sess, logdir, step):\n",
    "    model_name = 'model.ckpt'\n",
    "    checkpoint_path = os.path.join(logdir, model_name)\n",
    "    print('Storing checkpoint to {} ...'.format(logdir), end=\"\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    if not os.path.exists(logdir):\n",
    "        os.makedirs(logdir)\n",
    "\n",
    "    saver.save(sess, checkpoint_path, global_step=step)\n",
    "    print(' Done.')\n",
    "\n",
    "\n",
    "def load(saver, sess, logdir):\n",
    "    print(\"Trying to restore saved checkpoints from {} ...\".format(logdir),\n",
    "          end=\"\")\n",
    "\n",
    "    ckpt = tf.train.get_checkpoint_state(logdir)\n",
    "    if ckpt:\n",
    "        print(\"  Checkpoint found: {}\".format(ckpt.model_checkpoint_path))\n",
    "        global_step = int(ckpt.model_checkpoint_path\n",
    "                          .split('/')[-1]\n",
    "                          .split('-')[-1])\n",
    "        print(\"  Global step was: {}\".format(global_step))\n",
    "        print(\"  Restoring...\", end=\"\")\n",
    "        saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "        print(\" Done.\")\n",
    "        return global_step\n",
    "    else:\n",
    "        print(\" No checkpoint found.\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_default_logdir(logdir_root):\n",
    "    logdir = os.path.join(logdir_root, 'train', STARTED_DATESTRING)\n",
    "    return logdir\n",
    "\n",
    "\n",
    "def validate_directories(args):\n",
    "    \"\"\"Validate and arrange directory related arguments.\"\"\"\n",
    "\n",
    "    # Validation\n",
    "    if args.logdir and args.logdir_root:\n",
    "        raise ValueError(\"--logdir and --logdir_root cannot be \"\n",
    "                         \"specified at the same time.\")\n",
    "\n",
    "    if args.logdir and args.restore_from:\n",
    "        raise ValueError(\n",
    "            \"--logdir and --restore_from cannot be specified at the same \"\n",
    "            \"time. This is to keep your previous model from unexpected \"\n",
    "            \"overwrites.\\n\"\n",
    "            \"Use --logdir_root to specify the root of the directory which \"\n",
    "            \"will be automatically created with current date and time, or use \"\n",
    "            \"only --logdir to just continue the training from the last \"\n",
    "            \"checkpoint.\")\n",
    "\n",
    "    # Arrangement\n",
    "    logdir_root = args.logdir_root\n",
    "    if logdir_root is None:\n",
    "        logdir_root = LOGDIR_ROOT\n",
    "\n",
    "    logdir = args.logdir\n",
    "    if logdir is None:\n",
    "        logdir = get_default_logdir(logdir_root)\n",
    "        print('Using default logdir: {}'.format(logdir))\n",
    "\n",
    "    restore_from = args.restore_from\n",
    "    if restore_from is None:\n",
    "        # args.logdir and args.restore_from are exclusive,\n",
    "        # so it is guaranteed the logdir here is newly created.\n",
    "        restore_from = logdir\n",
    "\n",
    "    return {\n",
    "        'logdir': logdir,\n",
    "        'logdir_root': args.logdir_root,\n",
    "        'restore_from': restore_from\n",
    "    }\n",
    "\n",
    "\n",
    "def main():\n",
    "    args = get_arguments()\n",
    "\n",
    "    try:\n",
    "        directories = validate_directories(args)\n",
    "    except ValueError as e:\n",
    "        print(\"Some arguments are wrong:\")\n",
    "        print(str(e))\n",
    "        return\n",
    "\n",
    "    logdir = directories['logdir']\n",
    "    restore_from = directories['restore_from']\n",
    "\n",
    "    # Even if we restored the model, we will treat it as new training\n",
    "    # if the trained model is written into an arbitrary location.\n",
    "    is_overwritten_training = logdir != restore_from\n",
    "\n",
    "    with open(args.wavenet_params, 'r') as f:\n",
    "        wavenet_params = json.load(f)\n",
    "\n",
    "    # Create coordinator.\n",
    "    coord = tf.train.Coordinator()\n",
    "\n",
    "    # Load raw waveform from VCTK corpus.\n",
    "    with tf.name_scope('create_inputs'):\n",
    "        # Allow silence trimming to be skipped by specifying a threshold near\n",
    "        # zero.\n",
    "        silence_threshold = args.silence_threshold if args.silence_threshold > \\\n",
    "                                                      EPSILON else None\n",
    "\n",
    "        reader = AudioReader(\n",
    "            args.data_dir,\n",
    "            coord,\n",
    "            sample_rate=wavenet_params['sample_rate'],\n",
    "            receptive_field=WaveNetModel.calculate_receptive_field(wavenet_params[\"filter_width\"],\n",
    "                                                                   wavenet_params[\"dilations\"],\n",
    "                                                                   wavenet_params[\"scalar_input\"],\n",
    "                                                                   wavenet_params[\"initial_filter_width\"]),\n",
    "            sample_size=args.sample_size,\n",
    "            silence_threshold=silence_threshold)\n",
    "        audio_batch = reader.dequeue(args.batch_size)\n",
    "\n",
    "\n",
    "    # Create network.\n",
    "    net = WaveNetModel(\n",
    "        batch_size=args.batch_size,\n",
    "        dilations=wavenet_params[\"dilations\"],\n",
    "        filter_width=wavenet_params[\"filter_width\"],\n",
    "        residual_channels=wavenet_params[\"residual_channels\"],\n",
    "        dilation_channels=wavenet_params[\"dilation_channels\"],\n",
    "        skip_channels=wavenet_params[\"skip_channels\"],\n",
    "        quantization_channels=wavenet_params[\"quantization_channels\"],\n",
    "        use_biases=wavenet_params[\"use_biases\"],\n",
    "        scalar_input=wavenet_params[\"scalar_input\"],\n",
    "        initial_filter_width=wavenet_params[\"initial_filter_width\"],\n",
    "        histograms=args.histograms)\n",
    "\n",
    "    if args.l2_regularization_strength == 0:\n",
    "        args.l2_regularization_strength = None\n",
    "    loss = net.loss(input_batch=audio_batch,\n",
    "                    l2_regularization_strength=args.l2_regularization_strength)\n",
    "    optimizer = optimizer_factory[args.optimizer](\n",
    "                    learning_rate=args.learning_rate,\n",
    "                    momentum=args.momentum)\n",
    "    trainable = tf.trainable_variables()\n",
    "    optim = optimizer.minimize(loss, var_list=trainable)\n",
    "\n",
    "    # Set up logging for TensorBoard.\n",
    "    writer = tf.summary.FileWriter(logdir)\n",
    "    writer.add_graph(tf.get_default_graph())\n",
    "    run_metadata = tf.RunMetadata()\n",
    "    summaries = tf.summary.merge_all()\n",
    "\n",
    "    # Set up session\n",
    "    sess = tf.Session(config=tf.ConfigProto(log_device_placement=False))\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "\n",
    "    # Saver for storing checkpoints of the model.\n",
    "    saver = tf.train.Saver(var_list=tf.trainable_variables(), max_to_keep=args.max_checkpoints)\n",
    "\n",
    "    try:\n",
    "        saved_global_step = load(saver, sess, restore_from)\n",
    "        if is_overwritten_training or saved_global_step is None:\n",
    "            # The first training step will be saved_global_step + 1,\n",
    "            # therefore we put -1 here for new or overwritten trainings.\n",
    "            saved_global_step = -1\n",
    "\n",
    "    except:\n",
    "        print(\"Something went wrong while restoring checkpoint. \"\n",
    "              \"We will terminate training to avoid accidentally overwriting \"\n",
    "              \"the previous model.\")\n",
    "        raise\n",
    "\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "    reader.start_threads(sess)\n",
    "\n",
    "    step = None\n",
    "    last_saved_step = saved_global_step\n",
    "    try:\n",
    "        for step in range(saved_global_step + 1, args.num_steps):\n",
    "            start_time = time.time()\n",
    "            if args.store_metadata and step % 50 == 0:\n",
    "                # Slow run that stores extra information for debugging.\n",
    "                print('Storing metadata')\n",
    "                run_options = tf.RunOptions(\n",
    "                    trace_level=tf.RunOptions.FULL_TRACE)\n",
    "                summary, loss_value, _ = sess.run(\n",
    "                    [summaries, loss, optim],\n",
    "                    options=run_options,\n",
    "                    run_metadata=run_metadata)\n",
    "                writer.add_summary(summary, step)\n",
    "                writer.add_run_metadata(run_metadata,\n",
    "                                        'step_{:04d}'.format(step))\n",
    "                tl = timeline.Timeline(run_metadata.step_stats)\n",
    "                timeline_path = os.path.join(logdir, 'timeline.trace')\n",
    "                with open(timeline_path, 'w') as f:\n",
    "                    f.write(tl.generate_chrome_trace_format(show_memory=True))\n",
    "            else:\n",
    "                summary, loss_value, _ = sess.run([summaries, loss, optim])\n",
    "                writer.add_summary(summary, step)\n",
    "\n",
    "            duration = time.time() - start_time\n",
    "            print('step {:d} - loss = {:.3f}, ({:.3f} sec/step)'\n",
    "                  .format(step, loss_value, duration))\n",
    "\n",
    "            if step % args.checkpoint_every == 0:\n",
    "                save(saver, sess, logdir, step)\n",
    "                last_saved_step = step\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        # Introduce a line break after ^C is displayed so save message\n",
    "        # is on its own line.\n",
    "        print()\n",
    "    finally:\n",
    "        if step > last_saved_step:\n",
    "            save(saver, sess, logdir, step)\n",
    "        coord.request_stop()\n",
    "        coord.join(threads)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 22s, sys: 1.44 s, total: 1min 24s\n",
      "Wall time: 1min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_data = pd.read_csv('../_data/combined_csv/171212_87300samp_cry386_laugh703_with_ids.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mu_encode(x, mu=255, bitdepth=16):\n",
    "    x = np.divide(x, np.power(2, bitdepth-1))\n",
    "    x_scale = np.sign(x) * np.log(1 + mu*np.abs(x)) / np.log(1 + mu)\n",
    "    return np.round((x_scale + 1) / 2 * mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqIAAAGkCAYAAADqsEdzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBUEUAAAAtiCIAgAAwBb/P/gCt9b6lljvAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7facbdb64ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xx = np.arange(-32767, 32768)\n",
    "yy = mu_encode(xx)\n",
    "\n",
    "plt.plot(xx, yy)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sound_id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>87291</th>\n",
       "      <th>87292</th>\n",
       "      <th>87293</th>\n",
       "      <th>87294</th>\n",
       "      <th>87295</th>\n",
       "      <th>87296</th>\n",
       "      <th>87297</th>\n",
       "      <th>87298</th>\n",
       "      <th>87299</th>\n",
       "      <th>laugh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>72568</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>63</td>\n",
       "      <td>60</td>\n",
       "      <td>-3</td>\n",
       "      <td>-12</td>\n",
       "      <td>22</td>\n",
       "      <td>12</td>\n",
       "      <td>-19</td>\n",
       "      <td>-22</td>\n",
       "      <td>-28</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809</th>\n",
       "      <td>60799</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-69</td>\n",
       "      <td>20</td>\n",
       "      <td>121</td>\n",
       "      <td>40</td>\n",
       "      <td>-121</td>\n",
       "      <td>-123</td>\n",
       "      <td>26</td>\n",
       "      <td>182</td>\n",
       "      <td>184</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1038</th>\n",
       "      <td>105424</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-21</td>\n",
       "      <td>-33</td>\n",
       "      <td>2</td>\n",
       "      <td>-12</td>\n",
       "      <td>-9</td>\n",
       "      <td>14</td>\n",
       "      <td>-7</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942</th>\n",
       "      <td>162769</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>82</td>\n",
       "      <td>29</td>\n",
       "      <td>-2</td>\n",
       "      <td>27</td>\n",
       "      <td>7</td>\n",
       "      <td>-45</td>\n",
       "      <td>-31</td>\n",
       "      <td>15</td>\n",
       "      <td>33</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>377276</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>843</th>\n",
       "      <td>220670</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>221</td>\n",
       "      <td>116</td>\n",
       "      <td>72</td>\n",
       "      <td>97</td>\n",
       "      <td>82</td>\n",
       "      <td>61</td>\n",
       "      <td>60</td>\n",
       "      <td>11</td>\n",
       "      <td>-70</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>320472</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>-3</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>61064</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>32</td>\n",
       "      <td>53</td>\n",
       "      <td>62</td>\n",
       "      <td>65</td>\n",
       "      <td>62</td>\n",
       "      <td>42</td>\n",
       "      <td>22</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>41711</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>31</td>\n",
       "      <td>45</td>\n",
       "      <td>80</td>\n",
       "      <td>104</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>36</td>\n",
       "      <td>84</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>190504</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>46</td>\n",
       "      <td>46</td>\n",
       "      <td>47</td>\n",
       "      <td>41</td>\n",
       "      <td>27</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows  87302 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sound_id  0  1  2  3  4  5  6  7  8  ...    87291  87292  87293  87294  \\\n",
       "773      72568  0  0  0  0  0  0  0  0  0  ...       63     60     -3    -12   \n",
       "809      60799  0  0  0  0  0 -1  0  0  0  ...      -69     20    121     40   \n",
       "1038    105424  0  0  0  0  0  0  0  0  0  ...        0    -21    -33      2   \n",
       "942     162769  1  0  0  0  0  0  0  0 -1  ...       82     29     -2     27   \n",
       "517     377276  0  0 -1  0  0  0  0  0  0  ...        0      0      0      0   \n",
       "843     220670  0  0  0  0  0  0  0  0  0  ...      221    116     72     97   \n",
       "587     320472  0  0 -1  0  0  0  0  0  0  ...        8      1     -3     -1   \n",
       "889      61064  0  0  0  0  0  0  0  0  0  ...        7     18     32     53   \n",
       "559      41711  0  1  0  0  0 -1  0  0  0  ...       31     45     80    104   \n",
       "240     190504 -1  0  0  0  0  0  0  0  0  ...       46     46     47     41   \n",
       "\n",
       "      87295  87296  87297  87298  87299  laugh  \n",
       "773      22     12    -19    -22    -28    1.0  \n",
       "809    -121   -123     26    182    184    1.0  \n",
       "1038    -12     -9     14     -7      7    1.0  \n",
       "942       7    -45    -31     15     33    1.0  \n",
       "517       0      0      0      0      0    1.0  \n",
       "843      82     61     60     11    -70    1.0  \n",
       "587       2      2      2      4      1    1.0  \n",
       "889      62     65     62     42     22    1.0  \n",
       "559      44      1     18     36     84    1.0  \n",
       "240      27     16      6      4      8    0.0  \n",
       "\n",
       "[10 rows x 87302 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data2 = df_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "mu_encode() got an unexpected keyword argument 'inplace'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-e976276cf058>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_data2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'10000'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu_encode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/proj3/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   2353\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2354\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2355\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2357\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/src/inference.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/proj3/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   2340\u001b[0m         \u001b[0;31m# handle ufuncs and lambdas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2341\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkwds\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0margs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mufunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2342\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2343\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2344\u001b[0m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: mu_encode() got an unexpected keyword argument 'inplace'"
     ]
    }
   ],
   "source": [
    "df_data2['10000'].apply(mu_encode, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 15s, sys: 645 ms, total: 1min 15s\n",
      "Wall time: 1min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_data2 = df_data2.apply(mu_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sound_id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>87291</th>\n",
       "      <th>87292</th>\n",
       "      <th>87293</th>\n",
       "      <th>87294</th>\n",
       "      <th>87295</th>\n",
       "      <th>87296</th>\n",
       "      <th>87297</th>\n",
       "      <th>87298</th>\n",
       "      <th>87299</th>\n",
       "      <th>laugh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>338346</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>...</td>\n",
       "      <td>125.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>246309</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>...</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>219433</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>...</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>211528</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>...</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>211529</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>...</td>\n",
       "      <td>125.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>391181</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>...</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>405204</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>...</td>\n",
       "      <td>126.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>259606</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>...</td>\n",
       "      <td>126.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>259608</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>...</td>\n",
       "      <td>138.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>346663</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>...</td>\n",
       "      <td>129.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows  87302 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sound_id      0      1      2      3      4      5      6      7      8  \\\n",
       "0    338346  128.0  128.0  128.0  128.0  128.0  128.0  128.0  128.0  128.0   \n",
       "1    246309  128.0  128.0  128.0  128.0  128.0  128.0  128.0  128.0  128.0   \n",
       "2    219433  128.0  128.0  128.0  128.0  128.0  128.0  128.0  128.0  128.0   \n",
       "3    211528  128.0  128.0  128.0  128.0  128.0  128.0  128.0  128.0  128.0   \n",
       "4    211529  128.0  128.0  128.0  128.0  128.0  128.0  128.0  128.0  128.0   \n",
       "5    391181  128.0  128.0  128.0  128.0  128.0  128.0  128.0  128.0  128.0   \n",
       "6    405204  128.0  128.0  128.0  128.0  128.0  128.0  128.0  128.0  127.0   \n",
       "7    259606  128.0  128.0  128.0  128.0  128.0  128.0  128.0  128.0  128.0   \n",
       "8    259608  128.0  128.0  128.0  128.0  128.0  128.0  128.0  128.0  128.0   \n",
       "9    346663  128.0  128.0  128.0  128.0  128.0  128.0  128.0  128.0  128.0   \n",
       "\n",
       "   ...    87291  87292  87293  87294  87295  87296  87297  87298  87299  laugh  \n",
       "0  ...    125.0  124.0  124.0  124.0  124.0  125.0  124.0  125.0  126.0    0.0  \n",
       "1  ...    128.0  128.0  128.0  128.0  128.0  128.0  128.0  128.0  128.0    0.0  \n",
       "2  ...    128.0  128.0  128.0  128.0  127.0  127.0  127.0  127.0  127.0    0.0  \n",
       "3  ...    128.0  128.0  128.0  128.0  128.0  128.0  128.0  128.0  127.0    0.0  \n",
       "4  ...    125.0  123.0  124.0  124.0  125.0  126.0  123.0  122.0  122.0    0.0  \n",
       "5  ...    128.0  128.0  127.0  127.0  128.0  128.0  129.0  129.0  128.0    0.0  \n",
       "6  ...    126.0  124.0  125.0  129.0  129.0  130.0  131.0  129.0  127.0    0.0  \n",
       "7  ...    126.0  126.0  126.0  127.0  127.0  128.0  129.0  129.0  129.0    0.0  \n",
       "8  ...    138.0  127.0  118.0  119.0  129.0  136.0  137.0  136.0  131.0    0.0  \n",
       "9  ...    129.0  130.0  130.0  130.0  129.0  129.0  128.0  129.0  129.0    0.0  \n",
       "\n",
       "[10 rows x 87302 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_data2['sound_id'] = df_data['sound_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_data2['laugh'] = df_data['laugh']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sound_id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>87291</th>\n",
       "      <th>87292</th>\n",
       "      <th>87293</th>\n",
       "      <th>87294</th>\n",
       "      <th>87295</th>\n",
       "      <th>87296</th>\n",
       "      <th>87297</th>\n",
       "      <th>87298</th>\n",
       "      <th>87299</th>\n",
       "      <th>laugh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>338346</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-17</td>\n",
       "      <td>-18</td>\n",
       "      <td>-20</td>\n",
       "      <td>-22</td>\n",
       "      <td>-20</td>\n",
       "      <td>-17</td>\n",
       "      <td>-19</td>\n",
       "      <td>-17</td>\n",
       "      <td>-11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>246309</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>219433</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-3</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>211528</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>211529</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-12</td>\n",
       "      <td>-28</td>\n",
       "      <td>-22</td>\n",
       "      <td>-19</td>\n",
       "      <td>-14</td>\n",
       "      <td>-11</td>\n",
       "      <td>-25</td>\n",
       "      <td>-36</td>\n",
       "      <td>-38</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>391181</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-3</td>\n",
       "      <td>-5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>405204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-7</td>\n",
       "      <td>-21</td>\n",
       "      <td>-16</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "      <td>-3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>259606</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-8</td>\n",
       "      <td>-7</td>\n",
       "      <td>-7</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>259608</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>75</td>\n",
       "      <td>-5</td>\n",
       "      <td>-67</td>\n",
       "      <td>-59</td>\n",
       "      <td>7</td>\n",
       "      <td>59</td>\n",
       "      <td>69</td>\n",
       "      <td>55</td>\n",
       "      <td>21</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>346663</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows  87302 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sound_id  0  1  2  3  4  5  6  7  8  ...    87291  87292  87293  87294  \\\n",
       "0    338346  0  0  0  0  0  0  0  0  0  ...      -17    -18    -20    -22   \n",
       "1    246309  0  0  0  0  0  0  0  0  0  ...        0      0      0      0   \n",
       "2    219433  0  0  0  0  0  0  0  0  0  ...        3      1      1      1   \n",
       "3    211528  0  0  0  0  0  0  0  0  0  ...        1      1      1      2   \n",
       "4    211529  0  0  0  0  0  0  0  0  0  ...      -12    -28    -22    -19   \n",
       "5    391181  0  0  0  0  0  0  0  0  0  ...        2      1     -3     -5   \n",
       "6    405204  0  0  0  0  0  0  0  0 -1  ...       -7    -21    -16      7   \n",
       "7    259606  0  0  0  1  0  0  0  0  0  ...       -8     -7     -7     -4   \n",
       "8    259608  0  0  0  0  0  0  0  0  0  ...       75     -5    -67    -59   \n",
       "9    346663  0  0  0  0  0  0  1  0  0  ...       11     13     13     12   \n",
       "\n",
       "   87295  87296  87297  87298  87299  laugh  \n",
       "0    -20    -17    -19    -17    -11    0.0  \n",
       "1      0      0      0      0      0    0.0  \n",
       "2     -2     -1     -3     -4     -4    0.0  \n",
       "3      1      1      2      0     -1    0.0  \n",
       "4    -14    -11    -25    -36    -38    0.0  \n",
       "5      1      4      8      6      0    0.0  \n",
       "6     11     16     23      8     -3    0.0  \n",
       "7     -4      0      6     10      9    0.0  \n",
       "8      7     59     69     55     21    0.0  \n",
       "9      9      6      5      6      6    0.0  \n",
       "\n",
       "[10 rows x 87302 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_data2.to_csv('../_data/combined_csv/180116_87300samp_cry386_laugh703_with_ids_mu_law.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   1.,    0.,    0.,    0.,    1.,    0.,    0.,    0.,    0.,\n",
       "           1.,    2.,    0.,    1.,    5.,    6.,    2.,    2.,   11.,\n",
       "          12.,   11.,   19.,   34.,   38.,   53.,  101.,  397.,  167.,\n",
       "          81.,   40.,   29.,   18.,   11.,   13.,   10.,    5.,    5.,\n",
       "           5.,    2.,    2.,    1.,    0.,    0.,    0.,    0.,    1.,\n",
       "           0.,    1.,    0.,    0.,    1.]),\n",
       " array([-16941.  , -16281.74, -15622.48, -14963.22, -14303.96, -13644.7 ,\n",
       "        -12985.44, -12326.18, -11666.92, -11007.66, -10348.4 ,  -9689.14,\n",
       "         -9029.88,  -8370.62,  -7711.36,  -7052.1 ,  -6392.84,  -5733.58,\n",
       "         -5074.32,  -4415.06,  -3755.8 ,  -3096.54,  -2437.28,  -1778.02,\n",
       "         -1118.76,   -459.5 ,    199.76,    859.02,   1518.28,   2177.54,\n",
       "          2836.8 ,   3496.06,   4155.32,   4814.58,   5473.84,   6133.1 ,\n",
       "          6792.36,   7451.62,   8110.88,   8770.14,   9429.4 ,  10088.66,\n",
       "         10747.92,  11407.18,  12066.44,  12725.7 ,  13384.96,  14044.22,\n",
       "         14703.48,  15362.74,  16022.  ]),\n",
       " <a list of 50 Patch objects>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqIAAAGkCAYAAADqsEdzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRAEAAGDE/wOcDST93s5VSgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7facc3151160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def mu_law_encode(audio, quantization_channels):\n",
    "    '''Quantizes waveform amplitudes.'''\n",
    "    with tf.name_scope('encode'):\n",
    "        mu = tf.to_float(quantization_channels - 1)\n",
    "        # Perform mu-law companding transformation (ITU-T, 1988).\n",
    "        # Minimum operation is here to deal with rare large amplitudes caused\n",
    "        # by resampling.\n",
    "        safe_audio_abs = tf.minimum(tf.abs(audio), 1.0)\n",
    "        magnitude = tf.log1p(mu * safe_audio_abs) / tf.log1p(mu)\n",
    "        signal = tf.sign(audio) * magnitude\n",
    "        # Quantize signal to the specified number of levels.\n",
    "        return tf.to_int32((signal + 1) / 2 * mu + 0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (proj3)",
   "language": "python",
   "name": "proj3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
